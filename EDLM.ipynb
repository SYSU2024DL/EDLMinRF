{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ba5128-3e30-4d70-81d0-cbee2161efaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils import data \n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268c9175-2620-4892-a4ba-a6dff3933918",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transformer = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize(mean=[0.5,0.5,0.5],\n",
    "                                    std=[0.5,0.5,0.5]),\n",
    "])\n",
    "\n",
    "test_transformer = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize(mean=[0.5,0.5,0.5],\n",
    "                                    std=[0.5,0.5,0.5]),\n",
    "])\n",
    "\n",
    "verif_transformer = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize(mean=[0.5,0.5,0.5],\n",
    "                                    std=[0.5,0.5,0.5]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad52a46-488c-4b01-8378-234c49d0563c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset=torchvision.datasets.ImageFolder(\n",
    "  'D:/train',\n",
    "    transform=train_transformer\n",
    ")\n",
    "\n",
    "valid_dataset=torchvision.datasets.ImageFolder(\n",
    "  'D:/valid',\n",
    "   transform=valid_transformer\n",
    ")\n",
    "\n",
    "test_dataset=torchvision.datasets.ImageFolder(\n",
    "  'D:/test',\n",
    "   transform=test_transformer\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace06106-f8d5-4215-8d76-ac31e54bee5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Batch_size=16\n",
    "dl_train=torch.utils.data.DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=Batch_size,\n",
    "        shuffle=True\n",
    ")\n",
    "dl_valid=torch.utils.data.DataLoader(\n",
    "        valid_dataset,\n",
    "        batch_size=Batch_size,\n",
    "        shuffle=True\n",
    ")\n",
    "dl_test=torch.utils.data.DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=Batch_size,\n",
    "        shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f361ee0-70ed-4030-ae8c-52b94f487ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "####Efficient-net\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "####ensemble\n",
    "class CombinedModel(nn.Module):  \n",
    "    ''' Ensemble deep learning model '''\n",
    "    def __init__(self, num_classes):  \n",
    "        super(CombinedModel, self).__init__()  \n",
    "        \n",
    "        # ResNet Backbone  \n",
    "        self.resnet = torchvision.models.resnet18(pretrained=True)  \n",
    "        num_ftrs_resnet = self.resnet.fc.in_features  \n",
    "        self.resnet.fc = nn.Linear(num_ftrs_resnet, num_classes) \n",
    "        \n",
    "        # EfficientNet Backbone  \n",
    "        self.efficientnet = EfficientNet.from_pretrained('efficientnet-b7')\n",
    "        num_ftrs_efficientnet = self.efficientnet._fc.in_features  \n",
    "        self.efficientnet._fc = nn.Linear(num_ftrs_efficientnet, num_classes)  \n",
    "        \n",
    "        # Densenet Backbone\n",
    "        self.densenet = torchvision.models.densenet121(pretrained=True)  # 使用预训练的 DenseNet  \n",
    "        num_ftrs_densenet = self.densenet.classifier.in_features  \n",
    "        self.densenet.classifier = nn.Linear(num_ftrs_densenet, num_classes)\n",
    "        \n",
    "        #self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self, x):  \n",
    "        result_resnet = self.resnet(x)\n",
    "        result_efficientnet = self.efficientnet(x)\n",
    "        result_densenet = self.densenet(x)\n",
    "        #result_resnet = self.Softmax(self.resnet(x))\n",
    "        #result_efficientnet = self.Softmax(self.efficientnet(x))\n",
    "        #result_densenet = self.Softmax(self.densenet(x))\n",
    "        \n",
    "        output = (result_resnet + result_densenet + result_efficientnet ) / 3\n",
    "        return output  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7c588c-d59e-484b-84fe-db523a749168",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 2  \n",
    "model = CombinedModel(num_classes) \n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d43a4b-3695-4328-8e9f-4382a1c8691b",
   "metadata": {},
   "outputs": [],
   "source": [
    "###LOSS\n",
    "loss_fn=nn.CrossEntropyLoss() \n",
    "###Optimizer and learning rate\n",
    "from torch.optim import lr_scheduler\n",
    "optim=torch.optim.Adam(model.parameters(),lr=0.000002)\n",
    "scheduler = lr_scheduler.StepLR(optim,step_size=7,gamma = 0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92544ec3-fa2b-4ec2-acb8-9b41ae5be695",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    model.to('cuda')\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f189c8-d65a-4bc4-b99c-5a488cd2723e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(epoch, model, trainloader, validloader, testloader):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    running_loss = 0\n",
    "    model.train()\n",
    "    for x, y in tqdm(trainloader):\n",
    "        if torch.cuda.is_available():\n",
    "            x, y = x.to('cuda'), y.to('cuda')\n",
    "        y_pred = model(x)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        with torch.no_grad():\n",
    "            y_pred = torch.argmax(y_pred, dim=1)\n",
    "            correct += (y_pred == y).sum().item()\n",
    "            total += y.size(0)\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "    epoch_loss = running_loss / len(trainloader.dataset)\n",
    "    epoch_acc = correct / total\n",
    "        \n",
    "        \n",
    "    valid_correct = 0\n",
    "    valid_total = 0\n",
    "    valid_running_loss = 0 \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x, y in tqdm(validloader):\n",
    "            if torch.cuda.is_available():\n",
    "                x, y = x.to('cuda'), y.to('cuda')\n",
    "            y_pred = model(x)\n",
    "            loss = loss_fn(y_pred, y)\n",
    "            y_pred = torch.argmax(y_pred, dim=1)\n",
    "            test_correct += (y_pred == y).sum().item()\n",
    "            test_total += y.size(0)\n",
    "            test_running_loss += loss.item()\n",
    "    \n",
    "    epoch_valid_loss = valid_running_loss / len(validloader.dataset)\n",
    "    epoch_valid_acc = valid_correct / valid_total\n",
    "    \n",
    "    static_dict=model.state_dict()\n",
    "    torch.save(static_dict,'./checkpoints/{}_train_acc_{}_valid_acc_{}.pth'.format(epoch,round(epoch_acc, 3),round(epoch_valid_acc,3)))\n",
    "        \n",
    "    print('epoch: ', epoch, \n",
    "          'loss： ', round(epoch_loss, 3),\n",
    "          'accuracy:', round(epoch_acc, 3),\n",
    "          'valid_loss： ', round(epoch_valid_loss, 3),\n",
    "          'valid_accuracy:', round(epoch_valid_acc, 3)\n",
    "             )\n",
    "        \n",
    "    return epoch_loss, epoch_acc, epoch_valid_loss, epoch_valid_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70327d0-636b-44b8-80fd-17bee2beddf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5394145e-9b58-4575-8085-29adb2c5ca77",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = []\n",
    "train_acc = []\n",
    "valid_loss = []\n",
    "valid_acc = []\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    epoch_loss, epoch_acc, epoch_valid_loss, epoch_valid_acc  = fit(epoch,\n",
    "                                                                    model,\n",
    "                                                                    dl_train,\n",
    "                                                                    dl_valid)\n",
    "    train_loss.append(epoch_loss)\n",
    "    train_acc.append(epoch_acc)\n",
    "    valid_loss.append(epoch_valid_loss)\n",
    "    valid_acc.append(epoch_valid_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e121ada-ae55-46a5-bf02-be39c100d82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "####loss curve\n",
    "plt.plot(range(1, epochs+1), train_loss, label='train set', color='#0000FF')\n",
    "plt.plot(range(1, epochs+1), valid_loss, label='validation set', color='#FF0000')\n",
    "plt.title('Model loss function convergence curve')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41793d38-642a-4026-a57c-14a3ac3b86fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "###ACC\n",
    "plt.plot(range(1, epochs+1), train_acc, label='train set', color='#0000FF')\n",
    "plt.plot(range(1, epochs+1), valid_acc, label='validation set', color='#FF0000')\n",
    "plt.title('The accuracy of different deep learning nets in the training and validation set changes with epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accucary')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325668e7-002e-4161-a77c-44d8635f6164",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "model.train()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in dl_train:\n",
    "        inputs = inputs.to('cuda')\n",
    "        labels = labels.to('cuda')\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        \n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "###confusion matrix\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "print(cm) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc916956-119d-427d-957f-d3ae4b9a3985",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "all_preds1 = []\n",
    "all_labels1 = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in dl_valid:\n",
    "        inputs = inputs.to('cuda')\n",
    "        labels = labels.to('cuda')\n",
    "        \n",
    "        # 前向传播\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        # 获取预测结果\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        \n",
    "        # 收集预测值和真实标签\n",
    "        all_preds1.extend(preds.cpu().numpy())\n",
    "        all_labels1.extend(labels.cpu().numpy())\n",
    "###confusion matrix1\n",
    "cm1 = confusion_matrix(all_labels1, all_preds1)\n",
    "print(cm1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11019ac-f1bf-4805-8fcf-f5b7b2cbc44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "all_preds2 = []\n",
    "all_labels2 = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in dl_test:\n",
    "        inputs = inputs.to('cuda')\n",
    "        labels = labels.to('cuda')\n",
    "        \n",
    "        # 前向传播\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        # 获取预测结果\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        \n",
    "        # 收集预测值和真实标签\n",
    "        all_preds2.extend(preds.cpu().numpy())\n",
    "        all_labels2.extend(labels.cpu().numpy())\n",
    "\n",
    "###confusion matrix2\n",
    "cm2 = confusion_matrix(all_labels2, all_preds2)\n",
    "print(cm2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c04cf9-ecc0-4186-9f5b-7c5e767a267e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from sklearn.utils import resample\n",
    "TN = 35  # True Negatives\n",
    "TP = 31  # True Positives\n",
    "FP = 13 # False Positives\n",
    "FN = 17  # False Negatives\n",
    "\n",
    "# \n",
    "accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "sensitivity = TP / (TP + FN)\n",
    "specificity = TN / (TN + FP)\n",
    "NPV = TN / (TN + FN) if (TN + FN) > 0 else 0\n",
    "PPV = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "\n",
    "# 95%CI\n",
    "def calc_confidence_interval(successes, trials, confidence=0.95):\n",
    "    ci = sm.stats.proportion_confint(successes, trials, alpha=1-confidence, method='normal')\n",
    "    return ci\n",
    "#\n",
    "accuracy_ci = calc_confidence_interval(TP + TN, TP + TN + FP + FN)\n",
    "sensitivity_ci = calc_confidence_interval(TP, TP + FN)\n",
    "specificity_ci = calc_confidence_interval(TN, TN + FP)\n",
    "NPV_ci = calc_confidence_interval(TN, TN + FN)\n",
    "PPV_ci = calc_confidence_interval(TP, TP + FP)\n",
    "\n",
    "# \n",
    "print(\"Accuracy: {:.3f} (95% CI: [{:.3f}, {:.3f}])\".format(accuracy, accuracy_ci[0], accuracy_ci[1]))\n",
    "print(\"Sensitivity: {:.3f} (95% CI: [{:.3f}, {:.3f}])\".format(sensitivity, sensitivity_ci[0], sensitivity_ci[1]))\n",
    "print(\"Specificity: {:.3f} (95% CI: [{:.3f}, {:.3f}])\".format(specificity, specificity_ci[0], specificity_ci[1]))\n",
    "print(\"NPV: {:.3f} (95% CI: [{:.3f}, {:.3f}])\".format(NPV, NPV_ci[0], NPV_ci[1]))\n",
    "print(\"PPV: {:.3f} (95% CI: [{:.3f}, {:.3f}])\".format(PPV, PPV_ci[0], PPV_ci[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45256108-d698-4707-8719-06fe40757a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model,'EDLM.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
