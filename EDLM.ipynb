{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85db5cd4-9248-41f9-bb9d-acea5c90a019",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils import data \n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "import torchvision.models as models\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7cf719-150e-4ec7-9701-d5d316588c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transformer = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize(mean=[0.5,0.5,0.5],\n",
    "                                    std=[0.5,0.5,0.5]),\n",
    "])\n",
    "\n",
    "test_transformer = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize(mean=[0.5,0.5,0.5],\n",
    "                                    std=[0.5,0.5,0.5]),\n",
    "])\n",
    "\n",
    "verif_transformer = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize(mean=[0.5,0.5,0.5],\n",
    "                                    std=[0.5,0.5,0.5]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f74cd04-d5f2-425e-8836-24b9995cb502",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset=torchvision.datasets.ImageFolder(\n",
    "  'D:/train',\n",
    "    transform=train_transformer\n",
    ")\n",
    "test_dataset=torchvision.datasets.ImageFolder(\n",
    "  'D:/test',\n",
    "   transform=test_transformer\n",
    ")\n",
    "verif_dataset=torchvision.datasets.ImageFolder(\n",
    "  'D:/verif',\n",
    "   transform=verif_transformer\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2d067f-5863-48db-b1d4-46ce231e1db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8434e02-237a-488b-8dc0-a7ad4f676b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38708878-04cb-4283-a82f-ccea4fe06322",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_to_class={}\n",
    "for k,v in train_dataset.class_to_idx.items():\n",
    "    print(k,v)\n",
    "    id_to_class[v]=k\n",
    "id_to_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba65a8a6-be2e-4485-9144-3cb439091ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Batch_size=16\n",
    "dl_train=torch.utils.data.DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=Batch_size,\n",
    "        shuffle=True\n",
    ")\n",
    "dl_test=torch.utils.data.DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=Batch_size,\n",
    ")\n",
    "dl_verif=torch.utils.data.DataLoader(\n",
    "        verif_dataset,\n",
    "        batch_size=Batch_size,\n",
    "        shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3678d9-dd70-4668-835d-a5371686dd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombinedModel(nn.Module):  \n",
    "    def __init__(self, num_classes):  \n",
    "        super(CombinedModel, self).__init__()  \n",
    "             \n",
    "        # ResNet Backbone  \n",
    "        self.resnet = torchvision.models.resnet18(weights=models.ResNet18_Weights.DEFAULT)  \n",
    "        num_ftrs_resnet = self.resnet.fc.in_features  \n",
    "        self.resnet.fc = nn.Linear(num_ftrs_resnet, num_classes) \n",
    "        \n",
    "        # EfficientNet Backbone  \n",
    "        self.efficientnet = EfficientNet.from_pretrained('efficientnet-b7')\n",
    "        num_ftrs_efficientnet = self.efficientnet._fc.in_features  \n",
    "        self.efficientnet._fc = nn.Linear(num_ftrs_efficientnet, num_classes)  \n",
    "        \n",
    "        # Densenet Backbone\n",
    "        self.densenet = torchvision.models.densenet121(weights=models.DenseNet121_Weights.IMAGENET1K_V1) \n",
    "        num_ftrs_densenet = self.densenet.classifier.in_features  \n",
    "        self.densenet.classifier = nn.Linear(num_ftrs_densenet, num_classes) \n",
    "        \n",
    "    def forward(self, x):  \n",
    "        result_resnet = self.resnet(x)\n",
    "        result_efficientnet = self.efficientnet(x)\n",
    "        result_densenet = self.densenet(x)      \n",
    "        output = (result_resnet + result_densenet + result_efficientnet ) / 3\n",
    "        return output  \n",
    "num_classes = 2  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90378d66-b2ce-4846-a279-5e55a77e2f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CombinedModel(num_classes) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df5abe2-00a3-44be-ad5f-01924a384008",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn=nn.CrossEntropyLoss() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b9c923-d59a-411c-81ca-99a04e9bf811",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import lr_scheduler\n",
    "optim=torch.optim.Adam(model.parameters(),lr=0.000005)\n",
    "scheduler = lr_scheduler.StepLR(optim,step_size=5,gamma = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b805ff2-2b0b-43b3-85f9-7b04a010ca35",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    model.to('cuda')\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88fd0e1-f324-4bf9-9ccc-9a7f048d5969",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(epoch, model, trainloader, verifloader):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    running_loss = 0\n",
    "    model.train()\n",
    "    for x, y in tqdm(trainloader):\n",
    "        if torch.cuda.is_available():\n",
    "            x, y = x.to('cuda'), y.to('cuda')\n",
    "        y_pred = model(x)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        with torch.no_grad():\n",
    "            y_pred = torch.argmax(y_pred, dim=1)\n",
    "            correct += (y_pred == y).sum().item()\n",
    "            total += y.size(0)\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "    epoch_loss = running_loss / len(trainloader.dataset)\n",
    "    epoch_acc = correct / total\n",
    "        \n",
    "    verif_correct = 0\n",
    "    verif_total = 0\n",
    "    verif_running_loss = 0 \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x, y in tqdm(verifloader):\n",
    "            if torch.cuda.is_available():\n",
    "                x, y = x.to('cuda'), y.to('cuda')\n",
    "            y_pred = model(x)\n",
    "            loss = loss_fn(y_pred, y)\n",
    "            y_pred = torch.argmax(y_pred, dim=1)\n",
    "            verif_correct += (y_pred == y).sum().item()\n",
    "            verif_total += y.size(0)\n",
    "            verif_running_loss += loss.item()\n",
    "    \n",
    "    epoch_verif_loss = verif_running_loss / len(verifloader.dataset)\n",
    "    epoch_verif_acc = verif_correct / verif_total\n",
    "\n",
    "    static_dict=model.state_dict()\n",
    "    torch.save(static_dict,'./checkpoints/{}_dtrain_acc_{}_verif_acc_{}.pth'.format(epoch,round(epoch_acc, 3),round(epoch_verif_acc,3)))\n",
    "        \n",
    "    print('epoch: ', epoch, \n",
    "          'loss： ', round(epoch_loss, 3),\n",
    "          'accuracy:', round(epoch_acc, 3),\n",
    "          'verif_loss： ', round(epoch_verif_loss, 3),\n",
    "          'verif_accuracy:', round(epoch_verif_acc, 3))\n",
    "        \n",
    "    return epoch_loss, epoch_acc, epoch_verif_loss, epoch_verif_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0971a9-11ee-4871-83ff-8130492d2787",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e50a71e-4f5b-4612-9cc8-e7b6286f958b",
   "metadata": {},
   "outputs": [],
   "source": [
    "patience = 3  \n",
    "best_verif_loss = float('inf')\n",
    "early_stopping_counter = 0\n",
    "\n",
    "train_loss = []\n",
    "train_acc = []\n",
    "verif_loss = []\n",
    "verif_acc = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    epoch_loss, epoch_acc, epoch_verif_loss, epoch_verif_acc = fit(epoch,\n",
    "                                                                   model,\n",
    "                                                                   dl_train,\n",
    "                                                                   dl_verif)\n",
    "    train_loss.append(epoch_loss)\n",
    "    train_acc.append(epoch_acc)\n",
    "    verif_loss.append(epoch_verif_loss)\n",
    "    verif_acc.append(epoch_verif_acc)\n",
    "\n",
    "    if epoch_verif_loss < best_verif_loss:\n",
    "        best_verif_loss = epoch_verif_loss\n",
    "        early_stopping_counter = 0\n",
    "    else:\n",
    "        early_stopping_counter += 1\n",
    "        if early_stopping_counter >= patience:\n",
    "            print(f\"Early stopping at epoch {epoch}\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1054553b-4b86-460f-a722-69c619d5acbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(1, len(train_loss)+1), train_loss, label='Train set', color='#0000FF')\n",
    "plt.plot(range(1, len(verif_loss)+1), verif_loss, label='Validation set', color='#FF0000')\n",
    "plt.title('Model loss function convergence curve')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "SFig1 = plt.gcf() \n",
    "SFig1.savefig(r'D:\\ensem_LOSS.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06030a51-b3c4-48ed-859e-14473d74c709",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(1, len(train_acc)+1), train_acc, label='Train set', color='#0000FF')\n",
    "plt.plot(range(1, len(verif_acc)+1), verif_acc, label='Validation set', color='#FF0000')\n",
    "plt.title('The accuracy of different deep learning nets in the training and validation set changes with epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "Fig2 = plt.gcf()\n",
    "Fig2.savefig(r'D:\\ensemnet_acc.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1152599b-f0e5-4338-8004-66abb2d569fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in dl_train:\n",
    "        inputs = inputs.to('cuda')\n",
    "        labels = labels.to('cuda')\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        \n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "print(cm) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c19c91-dc75-4197-b616-c774b4ad585b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds2 = []\n",
    "all_labels2 = []\n",
    "all_pred_probs2 = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in dl_verif:\n",
    "        inputs = inputs.to('cuda')\n",
    "        labels = labels.to('cuda')\n",
    "\n",
    "        outputs = model(inputs) \n",
    "        \n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        \n",
    "        probs = F.softmax(outputs, dim=1)\n",
    "        \n",
    "        all_preds2.extend(preds.cpu().numpy())\n",
    "        all_labels2.extend(labels.cpu().numpy())\n",
    "        all_pred_probs2.extend(probs.cpu().numpy())\n",
    "\n",
    "cm2 = confusion_matrix(all_labels2, all_preds2)\n",
    "print(cm2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea11b172-ffe1-4144-a728-d6f45a28c6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds1 = []\n",
    "all_labels1 = []\n",
    "all_pred_probs1 = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in dl_test:\n",
    "        inputs = inputs.to('cuda')\n",
    "        labels = labels.to('cuda')\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        probs = F.softmax(outputs, dim=1)\n",
    "        \n",
    "        all_preds1.extend(preds.cpu().numpy())\n",
    "        all_labels1.extend(labels.cpu().numpy())\n",
    "        all_pred_probs1.extend(probs.cpu().numpy())\n",
    "\n",
    "cm1 = confusion_matrix(all_labels1, all_preds1)\n",
    "print(cm1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b7924b-6daa-49bb-9ae7-82eb50b1f987",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model,'EDLM.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150b59c7-6890-4438-90ce-d78f90af5d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1bb3487-e056-4abe-a157-12ca273e81de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test \n",
    "TN =     # nunmber of True Negatives \n",
    "TP =     # nunmber of True Positives\n",
    "FP =     # nunmber of False Positives\n",
    "FN =     # nunmber of False Negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f1d573-5b6f-4733-8e30-8ebf28699de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "sensitivity = TP / (TP + FN)\n",
    "specificity = TN / (TN + FP)\n",
    "NPV = TN / (TN + FN) if (TN + FN) > 0 else 0\n",
    "precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "\n",
    "def calc_confidence_interval(successes, trials, confidence=0.95):\n",
    "    ci = sm.stats.proportion_confint(successes, trials, alpha=1-confidence, method='wilson')\n",
    "    return ci\n",
    "\n",
    "accuracy_ci = calc_confidence_interval(TP + TN, TP + TN + FP + FN)\n",
    "sensitivity_ci = calc_confidence_interval(TP, TP + FN)\n",
    "specificity_ci = calc_confidence_interval(TN, TN + FP)\n",
    "NPV_ci = calc_confidence_interval(TN, TN + FN)\n",
    "precision_ci = calc_confidence_interval(TP, TP + FP)\n",
    "f1_score_ci = bootstrap_f1_score(TP, TN, FP, FN)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f} ({accuracy_ci[0]:.4f}-{accuracy_ci[1]:.4f})\")\n",
    "print(f\"Sensitivity: {sensitivity:.4f} ({sensitivity_ci[0]:.4f}-{sensitivity_ci[1]:.4f})\")\n",
    "print(f\"Specificity: {specificity:.4f} ({specificity_ci[0]:.4f}-{specificity_ci[1]:.4f})\")\n",
    "print(f\"NPV: {NPV:.4f} ({NPV_ci[0]:.4f}-{NPV_ci[1]:.4f})\")\n",
    "print(f\"Precision: {precision:.4f} ({precision_ci[0]:.4f}-{precision_ci[1]:.4f})\")\n",
    "print(f\"F1-score: {f1_score:.4f} ({f1_score_ci[0]:.4f}-{f1_score_ci[1]:.4f})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
